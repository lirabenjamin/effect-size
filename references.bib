
@article{cohen_power_1992,
	title = {A power primer},
	volume = {112},
	issn = {1939-1455},
	doi = {10.1037/0033-2909.112.1.155},
	abstract = {One possible reason for the continued neglect of statistical power analysis in research in the behavioral sciences is the inaccessibility of or difficulty with the standard material. A convenient, although not comprehensive, presentation of required sample sizes is provided. Effect-size indexes and conventional values for these are given for operationally defined small, medium, and large effects. The sample sizes necessary for .80 power to detect effects at these levels are tabled for 8 standard statistical tests: (1) the difference between independent means, (2) the significance of a product–moment correlation, (3) the difference between independent rs, (4) the sign test, (5) the difference between independent proportions, (6) chi-square tests for goodness of fit and contingency tables, (7) 1-way analysis of variance (ANOVA), and (8) the significance of a multiple or multiple partial correlation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Bulletin},
	author = {Cohen, Jacob},
	year = {1992},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Effect Size (Statistical), Statistical Analysis, Statistical Power},
	pages = {155--159},
	file = {Cohen1992.pdf:/Users/blira/Zotero/storage/2GI83Y32/Cohen1992.pdf:application/pdf;Snapshot:/Users/blira/Zotero/storage/T27WZGIV/1992-37683-001.html:text/html},
}


@article{bailey_persistence_2020,
	title = {Persistence and {Fade}-{Out} of {Educational}-{Intervention} {Effects}: {Mechanisms} and {Potential} {Solutions}},
	volume = {21},
	issn = {1529-1006},
	shorttitle = {Persistence and {Fade}-{Out} of {Educational}-{Intervention} {Effects}},
	url = {https://doi.org/10.1177/1529100620915848},
	doi = {10.1177/1529100620915848},
	abstract = {Some environmental influences, including intentional interventions, have shown persistent effects on psychological characteristics and other socially important outcomes years and even decades later. At the same time, it is common to find that the effects of life events or interventions diminish and even disappear completely, a phenomenon known as fade-out. We review the evidence for persistence and fade-out, drawing primarily on evidence from educational interventions. We conclude that (a) fade-out is widespread and often coexists with persistence; (b) fade-out is a substantive phenomenon, not merely a measurement artifact; and (c) persistence depends on the types of skills targeted, the institutional constraints and opportunities within the social context, and complementarities between interventions and subsequent environmental affordances. We discuss the implications of these conclusions for research and policy.},
	number = {2},
	urldate = {2023-07-12},
	journal = {Psychological Science in the Public Interest},
	author = {Bailey, Drew H. and Duncan, Greg J. and Cunha, Flávio and Foorman, Barbara R. and Yeager, David S.},
	month = oct,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {55--97},
	file = {Full Text PDF:/Users/blira/Zotero/storage/I6JKANMM/Bailey et al. - 2020 - Persistence and Fade-Out of Educational-Interventi.pdf:application/pdf},
}


@techreport{boyceElevenYearsStudent2023,
	type = {preprint},
	title = {Eleven years of student replication projects provide evidence on the correlates of replicability in psychology},
	url = {https://osf.io/dpyn6},
	abstract = {Cumulative scientific progress requires empirical results that are robust enough to support theory construction and extension. Yet in psychology, some prominent findings have failed to replicate, and large-scale studies suggest replicability issues are widespread. The identification of predictors of replication success is limited by the difficulty of conducting large samples of independent replication experiments, however: most investigations re-analyse the same set of {\textasciitilde}170 replications. We introduce a new dataset of 176 replications from students in a graduate-level methods course. Replication results were judged to be successful in 49\% of replications; of the 136 where effect sizes could be numerically compared, 46\% had point estimates within the prediction interval of the original outcome (versus the expected 95\%). Larger original effect sizes and within-participants designs were especially related to replication success. Our results indicate that, consistent with prior reports, the robustness of the psychology literature is low enough to limit cumulative progress by student investigators.},
	language = {en},
	urldate = {2023-08-26},
	institution = {PsyArXiv},
	author = {Boyce, Veronica and Mathur, Maya B and Frank, Michael C.},
	month = jul,
	year = {2023},
	doi = {10.31234/osf.io/dpyn6},
	file = {Boyce et al. - 2023 - Eleven years of student replication projects provi.pdf:/Users/blira/Zotero/storage/SN72YXW2/Boyce et al. - 2023 - Eleven years of student replication projects provi.pdf:application/pdf},
}


@article{gignac2016,
	title = {Effect size guidelines for individual differences researchers},
	volume = {102},
	issn = {01918869},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0191886916308194},
	doi = {10.1016/j.paid.2016.06.069},
	abstract = {Individual differences researchers very commonly report Pearson correlations between their variables of interest. Cohen (1988) provided guidelines for the purposes of interpreting the magnitude of a correlation, as well as estimating power. Speciﬁcally, r = 0.10, r = 0.30, and r = 0.50 were recommended to be considered small, medium, and large in magnitude, respectively. However, Cohen's effect size guidelines were based principally upon an essentially qualitative impression, rather than a systematic, quantitative analysis of data. Consequently, the purpose of this investigation was to develop a large sample of previously published meta-analytically derived correlations which would allow for an evaluation of Cohen's guidelines from an empirical perspective. Based on 708 meta-analytically derived correlations, the 25th, 50th, and 75th percentiles corresponded to correlations of 0.11, 0.19, and 0.29, respectively. Based on the results, it is suggested that Cohen's correlation guidelines are too exigent, as b3\% of correlations in the literature were found to be as large as r = 0.50. Consequently, in the absence of any other information, individual differences researchers are recommended to consider correlations of 0.10, 0.20, and 0.30 as relatively small, typical, and relatively large, in the context of a power analysis, as well as the interpretation of statistical results from a normative perspective.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Personality and Individual Differences},
	author = {Gignac, Gilles E. and Szodorai, Eva T.},
	month = nov,
	year = {2016},
	pages = {74--78},
	file = {Gignac and Szodorai - 2016 - Effect size guidelines for individual differences .pdf:/Users/blira/Zotero/storage/ZB72AZNQ/Gignac and Szodorai - 2016 - Effect size guidelines for individual differences .pdf:application/pdf},
}


@article{szucs2017,
	title = {Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature},
	author = {Szucs, Denes and Ioannidis, John P. A.},
	editor = {Wagenmakers, Eric-Jan},
	year = {2017},
	month = {03},
	date = {2017-03-02},
	journal = {PLOS Biology},
	pages = {e2000797},
	volume = {15},
	number = {3},
	doi = {10.1371/journal.pbio.2000797},
	url = {https://dx.plos.org/10.1371/journal.pbio.2000797},
	langid = {en}
}

@article{dellavigna2022,
	title = {RCTs to Scale: Comprehensive Evidence From Two Nudge Units},
	author = {DellaVigna, Stefano and Linos, Elizabeth},
	year = {2022},
	date = {2022},
	journal = {Econometrica},
	pages = {81--116},
	volume = {90},
	number = {1},
	doi = {10.3982/ECTA18709},
	url = {https://www.econometricsociety.org/doi/10.3982/ECTA18709},
	langid = {en}
}

@article{bosco2015,
	title = {Correlational effect size benchmarks.},
	author = {Bosco, Frank A. and Aguinis, Herman and Singh, Kulraj and Field, James G. and Pierce, Charles A.},
	year = {2015},
	month = {03},
	date = {2015-03},
	journal = {Journal of Applied Psychology},
	pages = {431--449},
	volume = {100},
	number = {2},
	doi = {10.1037/a0038047},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0038047},
	langid = {en}
}

@article{polanin2016,
	title = {Estimating the Difference Between Published and Unpublished Effect Sizes: A Meta-Review},
	author = {Polanin, Joshua R. and Tanner-Smith, Emily E. and Hennessy, Emily A.},
	year = {2016},
	month = {03},
	date = {2016-03-01},
	journal = {Review of Educational Research},
	pages = {207--236},
	volume = {86},
	number = {1},
	doi = {10.3102/0034654315582067},
	url = {https://doi.org/10.3102/0034654315582067},
	note = {Publisher: American Educational Research Association}
}

@article{götz2022,
	title = {Small Effects: The Indispensable Foundation for a Cumulative Psychological Science},
	author = {{Götz}, Friedrich M and Gosling, Samuel D and Rentfrow, Peter J},
	year = {2022},
	date = {2022},
	langid = {en}
}

@article{funder2019,
	title = {Evaluating Effect Size in Psychological Research: Sense and Nonsense},
	author = {Funder, David C. and Ozer, Daniel J.},
	year = {2019},
	month = {06},
	date = {2019-06},
	journal = {Advances in Methods and Practices in Psychological Science},
	pages = {156--168},
	volume = {2},
	number = {2},
	doi = {10.1177/2515245919847202},
	url = {http://journals.sagepub.com/doi/10.1177/2515245919847202},
	langid = {en}
}

@article{abdulkadiroglu2016,
	title = {Charters without Lotteries: Testing Takeovers in New Orleans and Boston},
	author = {{Abdulkadiro{\u{g}}lu}, Atila and Angrist, Joshua D. and Hull, Peter D. and Pathak, Parag A.},
	year = {2016},
	month = {07},
	date = {2016-07-01},
	journal = {American Economic Review},
	pages = {1878--1920},
	volume = {106},
	number = {7},
	doi = {10.1257/aer.20150479},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.20150479},
	langid = {en}
}

@article{opensciencecollaboration2015,
	title = {Estimating the reproducibility of psychological science},
	author = {Open Science Collaboration, },
	year = {2015},
	month = {08},
	date = {2015-08-28},
	journal = {Science},
	pages = {aac4716},
	volume = {349},
	number = {6251},
	doi = {10.1126/science.aac4716},
	url = {https://www.science.org/doi/10.1126/science.aac4716},
	langid = {en}
}

@article{salganik2020,
	title = {Measuring the predictability of life outcomes with a scientific mass collaboration},
	author = {Salganik, Matthew J. and Lundberg, Ian and Kindel, Alexander T. and Ahearn, Caitlin E. and Al-Ghoneim, Khaled and Almaatouq, Abdullah and Altschul, Drew M. and Brand, Jennie E. and Carnegie, Nicole Bohme and Compton, Ryan James and Datta, Debanjan and Davidson, Thomas and Filippova, Anna and Gilroy, Connor and Goode, Brian J. and Jahani, Eaman and Kashyap, Ridhi and Kirchner, Antje and McKay, Stephen and Morgan, Allison C. and Pentland, Alex and Polimis, Kivan and Raes, Louis and Rigobon, Daniel E. and Roberts, Claudia V. and Stanescu, Diana M. and Suhara, Yoshihiko and Usmani, Adaner and Wang, Erik H. and Adem, Muna and Alhajri, Abdulla and AlShebli, Bedoor and Amin, Redwane and Amos, Ryan B. and Argyle, Lisa P. and Baer-Bositis, Livia and {Büchi}, Moritz and Chung, Bo-Ryehn and Eggert, William and Faletto, Gregory and Fan, Zhilin and Freese, Jeremy and Gadgil, Tejomay and {Gagné}, Josh and Gao, Yue and Halpern-Manners, Andrew and Hashim, Sonia P. and Hausen, Sonia and He, Guanhua and Higuera, Kimberly and Hogan, Bernie and Horwitz, Ilana M. and Hummel, Lisa M. and Jain, Naman and Jin, Kun and Jurgens, David and Kaminski, Patrick and Karapetyan, Areg and Kim, E. H. and Leizman, Ben and Liu, Naijia and {Möser}, Malte and Mack, Andrew E. and Mahajan, Mayank and Mandell, Noah and Marahrens, Helge and Mercado-Garcia, Diana and Mocz, Viola and Mueller-Gastell, Katariina and Musse, Ahmed and Niu, Qiankun and Nowak, William and Omidvar, Hamidreza and Or, Andrew and Ouyang, Karen and Pinto, Katy M. and Porter, Ethan and Porter, Kristin E. and Qian, Crystal and Rauf, Tamkinat and Sargsyan, Anahit and Schaffner, Thomas and Schnabel, Landon and Schonfeld, Bryan and Sender, Ben and Tang, Jonathan D. and Tsurkov, Emma and van Loon, Austin and Varol, Onur and Wang, Xiafei and Wang, Zhi and Wang, Julia and Wang, Flora and Weissman, Samantha and Whitaker, Kirstie and Wolters, Maria K. and Woon, Wei Lee and Wu, James and Wu, Catherine and Yang, Kengran and Yin, Jingwen and Zhao, Bingyu and Zhu, Chenyun and Brooks-Gunn, Jeanne and Engelhardt, Barbara E. and Hardt, Moritz and Knox, Dean and Levy, Karen and Narayanan, Arvind and Stewart, Brandon M. and Watts, Duncan J. and McLanahan, Sara},
	year = {2020},
	month = {04},
	date = {2020-04-14},
	journal = {Proceedings of the National Academy of Sciences},
	pages = {8398--8403},
	volume = {117},
	number = {15},
	doi = {10.1073/pnas.1915006117},
	url = {https://pnas.org/doi/full/10.1073/pnas.1915006117},
	langid = {en}
}

@article{ahadi1989,
	title = {Multiple determinants and effect size},
	author = {Ahadi, Stephan and Diener, Edward},
	year = {1989},
	date = {1989},
	journal = {Journal of Personality and Social Psychology},
	pages = {398--406},
	volume = {56},
	number = {3},
	doi = {10.1037/0022-3514.56.3.398}
}

@article{dalton2012,
	title = {Revisiting the file drawer problem in meta-analysis: An assessment of published and nonpublished correlation matrices: Personnel Psychology},
	author = {Dalton, Dan R. and Aguinis, Herman and Dalton, Catherine M. and Bosco, Frank A. and Pierce, Charles A.},
	year = {2012},
	month = {06},
	date = {2012-06},
	journal = {Personnel Psychology},
	pages = {221--249},
	volume = {65},
	number = {2},
	doi = {10.1111/j.1744-6570.2012.01243.x},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1744-6570.2012.01243.x},
	langid = {en}
}
